from ast import pattern
import re
import pandas as pd
import numpy as np
import emoji
from collections import Counter
import matplotlib.pyplot as plt
from PIL import Image
from pickle import TRUE
import tkinter as tk
from tkinter import filedialog
#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator


# Code to extract the date from the chat message
def date_time(s):
    pattern = '^([0-9]+)(\/)([0-9]+)(\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'
# re means regular expresion used to check the patter into the file
    result = re.match(pattern, s)
    if result:
        return True
    return False


# Find Authors or Contacts
def find_author(s):
    s = s.split(":")
    if len(s) == 2:
        return True
    else:
        return False


#Finding Messages
def getDatapoint(line):
    splitline = line.split(" - ")
    dateTime = splitline[0]
    date, time = dateTime.split(",")
    message = " ".join(splitline[1:])
    if find_author(message):
        splitmessage = message.split(": ")
        author = splitmessage[0]
        message = " ".join(splitmessage[1:])
    else:
        author = None
    return date, time, author, message


# This piece of code will prompt the user to imput
# the file that will be used to analyze the sentiment.
root = tk.Tk()
root.withdraw()
conversation = filedialog.askopenfilename()


data = []
with open(conversation, encoding="utf-8") as fp:
    fp.readline()
    messageBuffer = []
    date, time, author = None, None, None
    while True:
        line = fp.readline()
        if not line:
            break
        line = line.strip()
        if date_time(line):
            if len(messageBuffer) > 0:
                data.append([date, time, author, ' '.join(messageBuffer)])
            messageBuffer.clear()
            date, time, author, message = getDatapoint(line)
            messageBuffer.append(message)
        else:
            messageBuffer.append(line)

            
df = pd.DataFrame(data, columns=["Date", 'Time', 'Author', 'Message'])
df['Date'] = pd.to_datetime(df['Date'])

data = df.dropna()
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk
nltk.downloader.download('vader_lexicon')
sentiments = SentimentIntensityAnalyzer()
data["Positive"] = [sentiments.polarity_scores(i)["pos"] for i in data["Message"]]
data["Negative"] = [sentiments.polarity_scores(i)["neg"] for i in data["Message"]]
data["Neutral"] = [sentiments.polarity_scores(i)["neu"] for i in data["Message"]]
print(data.head())


# Here is where we calculate the values of sentiment
x = sum(data["Positive"])
y = sum(data["Negative"])
z = sum(data["Neutral"])

def sentiment_score(a, b, c):
    if (a>b) and (a>c):
        print("Positive ğŸ˜Š ")
    elif (b>a) and (b>c):
        print("Negative ğŸ˜  ")
    else:
        print("Neutral ğŸ™‚ ")
sentiment_score(x, y, z)
